{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3080cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Semua metrik + TP/FP/FN/TN berhasil disimpan ke: c:\\Users\\Deore Mufrad\\Documents\\Tugas Akhir\\Automasi\\PAKE RULE BASED\\9. BACKUP 9 (KODE LAMA & BARU) + (TA)\\BARU\\Code\\Code Rapi Fix\\03_Output\\Hasil_ML_Cross_Validation\\Hasil_ML_CrossValidation_50.txt\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# === RANDOM FOREST CROSS-VALIDATION 50 TOPOLOGI ===\n",
    "# === Dengan Semua Metrik Evaluasi + TP/FP/FN/TN ===\n",
    "# === Output mirip evaluasi Rule-Based              ===\n",
    "# ==========================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    multilabel_confusion_matrix, classification_report, hamming_loss\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "\n",
    "# ================== PATH ==================\n",
    "CUR_DIR = os.getcwd()\n",
    "ROOT_DIR = os.path.dirname(CUR_DIR)\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, \"03_Output\", \"Data_ML_Labeled\")\n",
    "hasil_ml_dir = os.path.join(ROOT_DIR, \"03_Output\", \"Hasil_ML_Cross_Validation\")\n",
    "os.makedirs(hasil_ml_dir, exist_ok=True)\n",
    "\n",
    "output_txt = os.path.join(hasil_ml_dir, \"Hasil_ML_CrossValidation_50.txt\")\n",
    "\n",
    "# ================== URUTAN LABEL (SAMA DENGAN RULE-BASED) ==================\n",
    "LABELS_ORDER = [\n",
    "    \"HelloMismatch\",\n",
    "    \"DeadMismatch\",\n",
    "    \"NetworkTypeMismatch\",\n",
    "    \"AreaMismatch\",\n",
    "    \"AuthMismatch\",\n",
    "    \"AuthKeyMismatch\",\n",
    "    \"MTUMismatch\",\n",
    "    \"PassiveMismatch\",\n",
    "    \"RedistributeMismatch\",\n",
    "    \"RouterIDMismatch\",\n",
    "]\n",
    "\n",
    "# ================== LOAD 50 FILE TOPO ==================\n",
    "csv_files = sorted(\n",
    "    [f for f in os.listdir(data_dir) if f.startswith(\"topologi_\") and f.endswith(\".csv\")],\n",
    "    key=lambda x: int(x.split(\"_\")[1].split(\".\")[0])\n",
    ")\n",
    "\n",
    "selected_files = csv_files[:50]\n",
    "\n",
    "df_list = []\n",
    "for f in selected_files:\n",
    "    topo_num = int(f.split(\"_\")[1].split(\".\")[0])\n",
    "    temp = pd.read_csv(os.path.join(data_dir, f))\n",
    "    temp[\"topologi\"] = topo_num\n",
    "    df_list.append(temp)\n",
    "\n",
    "df_all = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
    "\n",
    "# ================== TARGET & FEATURE ==================\n",
    "target_cols = LABELS_ORDER[:]  # pakai urutan yang sama dengan rule-based\n",
    "\n",
    "exclude_cols = [\n",
    "    \"router_a\", \"router_b\", \"interface_a\", \"interface_b\",\n",
    "    \"ip_a\", \"ip_b\", \"subnet_a\", \"subnet_b\",\n",
    "    \"neighbor_a\", \"neighbor_b\", \"topologi\"\n",
    "] + target_cols\n",
    "\n",
    "feature_cols = [c for c in df_all.columns if c not in exclude_cols]\n",
    "\n",
    "# encode object columns\n",
    "df_encoded = df_all.copy()\n",
    "for col in feature_cols:\n",
    "    if df_encoded[col].dtype == \"object\":\n",
    "        df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col].astype(str))\n",
    "\n",
    "# ================== CROSS VALIDATION ==================\n",
    "results = []\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for topo in sorted(df_encoded[\"topologi\"].unique()):\n",
    "\n",
    "    df_train = df_encoded[df_encoded[\"topologi\"] != topo]\n",
    "    df_test  = df_encoded[df_encoded[\"topologi\"] == topo]\n",
    "\n",
    "    if df_train.empty or df_test.empty:\n",
    "        continue\n",
    "\n",
    "    X_train, y_train = df_train[feature_cols], df_train[target_cols].astype(int)\n",
    "    X_test,  y_test  = df_test[feature_cols], df_test[target_cols].astype(int)\n",
    "\n",
    "    # Train Random Forest (multi-output)\n",
    "    model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pd.DataFrame(model.predict(X_test), columns=target_cols, index=y_test.index)\n",
    "\n",
    "    # ===== PER-TOPO METRICS =====\n",
    "    subset_acc = accuracy_score(y_test, y_pred)\n",
    "    hamming_l = hamming_loss(y_test, y_pred)\n",
    "    hamming_acc = 1 - hamming_l\n",
    "\n",
    "    micro_prec = precision_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "    micro_rec  = recall_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "    micro_f1   = f1_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "\n",
    "    macro_prec = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    macro_rec  = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    macro_f1   = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    weighted_prec = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    weighted_rec  = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    weighted_f1   = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    results.append({\n",
    "        \"topologi\": topo,\n",
    "        \"subset_accuracy\": subset_acc,\n",
    "        \"hamming_accuracy\": hamming_acc,\n",
    "        \"hamming_loss\": hamming_l,\n",
    "        \"micro_precision\": micro_prec,\n",
    "        \"micro_recall\": micro_rec,\n",
    "        \"micro_f1\": micro_f1,\n",
    "        \"macro_precision\": macro_prec,\n",
    "        \"macro_recall\": macro_rec,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"weighted_precision\": weighted_prec,\n",
    "        \"weighted_recall\": weighted_rec,\n",
    "        \"weighted_f1\": weighted_f1\n",
    "    })\n",
    "\n",
    "    all_y_true.append(y_test)\n",
    "    all_y_pred.append(y_pred)\n",
    "\n",
    "# ================== GLOBAL METRICS (GABUNG SEMUA BARIS) ==================\n",
    "df_results = pd.DataFrame(results)\n",
    "summary_cv_mean = df_results.mean(numeric_only=True)  # rata-rata per-topologi (fold)\n",
    "\n",
    "y_true_all = pd.concat(all_y_true, ignore_index=True)\n",
    "y_pred_all = pd.concat(all_y_pred, ignore_index=True)\n",
    "\n",
    "# confusion matrix per label\n",
    "mcm = multilabel_confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "def safe_div(a, b):\n",
    "    return a / b if b else 0.0\n",
    "\n",
    "per_label = OrderedDict()\n",
    "sum_tp = sum_fp = sum_fn = sum_tn = 0\n",
    "\n",
    "for i, label in enumerate(target_cols):\n",
    "    TN, FP, FN, TP = mcm[i].ravel()\n",
    "\n",
    "    support_pos = TP + FN\n",
    "    support_neg = TN + FP\n",
    "    support_all = support_pos + support_neg\n",
    "\n",
    "    prec = safe_div(TP, TP + FP)\n",
    "    rec  = safe_div(TP, TP + FN)\n",
    "    f1   = safe_div(2 * prec * rec, (prec + rec))\n",
    "    acc  = safe_div(TP + TN, support_all)\n",
    "\n",
    "    per_label[label] = {\n",
    "        \"tp\": TP,\n",
    "        \"fp\": FP,\n",
    "        \"fn\": FN,\n",
    "        \"tn\": TN,\n",
    "        \"precision\": round(prec, 4),\n",
    "        \"recall\": round(rec, 4),\n",
    "        \"f1\": round(f1, 4),\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"support_pos\": int(support_pos),\n",
    "        \"support_neg\": int(support_neg),\n",
    "        \"support_all\": int(support_all),\n",
    "    }\n",
    "\n",
    "    sum_tp += TP\n",
    "    sum_fp += FP\n",
    "    sum_fn += FN\n",
    "    sum_tn += TN\n",
    "\n",
    "# macro dari per_label\n",
    "if per_label:\n",
    "    macro_p = sum(v[\"precision\"] for v in per_label.values()) / len(per_label)\n",
    "    macro_r = sum(v[\"recall\"]    for v in per_label.values()) / len(per_label)\n",
    "    macro_f1= sum(v[\"f1\"]        for v in per_label.values()) / len(per_label)\n",
    "    macro_acc = sum(v[\"accuracy\"] for v in per_label.values()) / len(per_label)\n",
    "else:\n",
    "    macro_p = macro_r = macro_f1 = macro_acc = 0.0\n",
    "\n",
    "# micro dari agregat TP/FP/FN/TN semua label\n",
    "micro_p = safe_div(sum_tp, sum_tp + sum_fp)\n",
    "micro_r = safe_div(sum_tp, sum_tp + sum_fn)\n",
    "micro_f1= safe_div(2 * micro_p * micro_r, (micro_p + micro_r))\n",
    "micro_jaccard = safe_div(sum_tp, (sum_tp + sum_fp + sum_fn))\n",
    "micro_acc_std  = safe_div(sum_tp + sum_tn, (sum_tp + sum_fp + sum_fn + sum_tn))\n",
    "\n",
    "# subset accuracy global (rata2 per-topologi)\n",
    "subset_acc_mean = float(summary_cv_mean[\"subset_accuracy\"])\n",
    "hamming_acc_mean = float(summary_cv_mean[\"hamming_accuracy\"])\n",
    "\n",
    "summary_global = {\n",
    "    \"macro\": {\n",
    "        \"precision\": round(macro_p, 4),\n",
    "        \"recall\": round(macro_r, 4),\n",
    "        \"f1\": round(macro_f1, 4),\n",
    "        \"accuracy\": round(macro_acc, 4),\n",
    "    },\n",
    "    \"micro\": {\n",
    "        \"precision\": round(micro_p, 4),\n",
    "        \"recall\": round(micro_r, 4),\n",
    "        \"f1\": round(micro_f1, 4),\n",
    "        \"accuracy_jaccard\": round(micro_jaccard, 4),\n",
    "        \"accuracy_standard\": round(micro_acc_std, 4),\n",
    "    },\n",
    "    \"global_counts\": {\n",
    "        \"tp_total\": int(sum_tp),\n",
    "        \"fp_total\": int(sum_fp),\n",
    "        \"fn_total\": int(sum_fn),\n",
    "        \"tn_total\": int(sum_tn),\n",
    "    },\n",
    "    \"subset_accuracy\": {\n",
    "        \"mean_exact_match\": round(subset_acc_mean, 4),\n",
    "        \"mean_hamming_accuracy\": round(hamming_acc_mean, 4),\n",
    "        \"num_samples\": int(len(y_true_all)),\n",
    "        \"num_topologies\": int(len(df_results)),\n",
    "    },\n",
    "}\n",
    "\n",
    "# classification report (opsional, tetap dipertahankan)\n",
    "report = classification_report(\n",
    "    y_true_all, y_pred_all,\n",
    "    target_names=LABELS_ORDER,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "# ================== SAVE OUTPUT ==================\n",
    "with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    f.write(\"=== HASIL RANDOM FOREST CROSS-VALIDATION (50 Topologi) ===\\n\\n\")\n",
    "\n",
    "    # ---- Ringkasan per-topologi (fold CV) ----\n",
    "    f.write(\"== Ringkasan Per Topologi (Fold CV) ==\\n\")\n",
    "    f.write(df_results.to_string(index=False))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    # ---- Per-label (format mirip rule-based) ----\n",
    "    f.write(\"\\n== Per Label (Global, gabungan 50 topologi) ==\\n\")\n",
    "    f.write(\"Label                  | TP  FP  FN  TN  | Prec   Rec    F1     Acc    | Pos  Neg  All\\n\")\n",
    "    f.write(\"-\" * 96 + \"\\n\")\n",
    "    for lbl in LABELS_ORDER:\n",
    "        v = per_label[lbl]\n",
    "        f.write(\n",
    "            f\"{lbl:22} | \"\n",
    "            f\"{v['tp']:3} {v['fp']:3} {v['fn']:3} {v['tn']:3} | \"\n",
    "            f\"{v['precision']:.4f} {v['recall']:.4f} {v['f1']:.4f} {v['accuracy']:.4f} | \"\n",
    "            f\"{v['support_pos']:4} {v['support_neg']:4} {v['support_all']:4}\\n\"\n",
    "        )\n",
    "\n",
    "    # ---- Rata-rata macro/micro ----\n",
    "    f.write(\"\\n== Rata-rata (Macro) ==\\n\")\n",
    "    f.write(f\"Macro Precision       : {summary_global['macro']['precision']}\\n\")\n",
    "    f.write(f\"Macro Recall          : {summary_global['macro']['recall']}\\n\")\n",
    "    f.write(f\"Macro F1-Score        : {summary_global['macro']['f1']}\\n\")\n",
    "    f.write(f\"Macro Accuracy        : {summary_global['macro']['accuracy']}\\n\")\n",
    "\n",
    "    f.write(\"\\n== Metrik Mikro (Global) ==\\n\")\n",
    "    f.write(f\"Micro Precision       : {summary_global['micro']['precision']}\\n\")\n",
    "    f.write(f\"Micro Recall          : {summary_global['micro']['recall']}\\n\")\n",
    "    f.write(f\"Micro F1-Score        : {summary_global['micro']['f1']}\\n\")\n",
    "    f.write(f\"Micro Accuracy Jaccard: {summary_global['micro']['accuracy_jaccard']}\\n\")\n",
    "    f.write(f\"Micro Accuracy Std    : {summary_global['micro']['accuracy_standard']}\\n\")\n",
    "\n",
    "    # ---- TN & subset accuracy (mirip rule-based) ----\n",
    "    f.write(\"\\n== TN & Subset Accuracy ==\\n\")\n",
    "    f.write(\n",
    "        f\"Total TP/FP/FN/TN     : \"\n",
    "        f\"{summary_global['global_counts']['tp_total']}/\"\n",
    "        f\"{summary_global['global_counts']['fp_total']}/\"\n",
    "        f\"{summary_global['global_counts']['fn_total']}/\"\n",
    "        f\"{summary_global['global_counts']['tn_total']}\\n\"\n",
    "    )\n",
    "    f.write(\n",
    "        f\"Subset Accuracy (Exact Match, mean per topologi) : \"\n",
    "        f\"{summary_global['subset_accuracy']['mean_exact_match']}\\n\"\n",
    "    )\n",
    "    f.write(\n",
    "        f\"Hamming Accuracy (mean per topologi)            : \"\n",
    "        f\"{summary_global['subset_accuracy']['mean_hamming_accuracy']}\\n\"\n",
    "    )\n",
    "    f.write(\n",
    "        f\"Total Sampel (baris dataset)                   : \"\n",
    "        f\"{summary_global['subset_accuracy']['num_samples']}\\n\"\n",
    "    )\n",
    "    f.write(\n",
    "        f\"Total Topologi (fold CV)                       : \"\n",
    "        f\"{summary_global['subset_accuracy']['num_topologies']}\\n\"\n",
    "    )\n",
    "\n",
    "    # ---- Classification report (opsional) ----\n",
    "    f.write(\"\\n=== CLASSIFICATION REPORT (GLOBAL) ===\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "    f.write(\"\\nWaktu Eksekusi: \" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "print(f\"[✓] Semua metrik + TP/FP/FN/TN berhasil disimpan ke: {output_txt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9663c0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Semua metrik + TP/FP/FN/TN berhasil disimpan ke: c:\\Users\\Deore Mufrad\\Documents\\Tugas Akhir\\Automasi\\PAKE RULE BASED\\9. BACKUP 9 (KODE LAMA & BARU) + (TA)\\BARU\\Code\\Code Rapi Fix\\03_Output\\Hasil_ML_Cross_Validation\\Hasil_ML_CrossValidation_100.txt\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# === RANDOM FOREST CROSS-VALIDATION 100 TOPOLOGI ===\n",
    "# === Dengan Semua Metrik Evaluasi + TP/FP/FN/TN ===\n",
    "# === Output mirip evaluasi Rule-Based              ===\n",
    "# ==========================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    multilabel_confusion_matrix, classification_report, hamming_loss\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "\n",
    "# ================== PATH ==================\n",
    "CUR_DIR = os.getcwd()\n",
    "ROOT_DIR = os.path.dirname(CUR_DIR)\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, \"03_Output\", \"Data_ML_Labeled\")\n",
    "hasil_ml_dir = os.path.join(ROOT_DIR, \"03_Output\", \"Hasil_ML_Cross_Validation\")\n",
    "os.makedirs(hasil_ml_dir, exist_ok=True)\n",
    "\n",
    "output_txt = os.path.join(hasil_ml_dir, \"Hasil_ML_CrossValidation_100.txt\")\n",
    "\n",
    "# ================== URUTAN LABEL (SAMA DENGAN RULE-BASED) ==================\n",
    "LABELS_ORDER = [\n",
    "    \"HelloMismatch\",\n",
    "    \"DeadMismatch\",\n",
    "    \"NetworkTypeMismatch\",\n",
    "    \"AreaMismatch\",\n",
    "    \"AuthMismatch\",\n",
    "    \"AuthKeyMismatch\",\n",
    "    \"MTUMismatch\",\n",
    "    \"PassiveMismatch\",\n",
    "    \"RedistributeMismatch\",\n",
    "    \"RouterIDMismatch\",\n",
    "]\n",
    "\n",
    "# ================== LOAD SEMUA FILE TOPOLOGI ==================\n",
    "csv_files = sorted(\n",
    "    [f for f in os.listdir(data_dir) if f.startswith(\"topologi_\") and f.endswith(\".csv\")],\n",
    "    key=lambda x: int(x.split(\"_\")[1].split(\".\")[0])\n",
    ")\n",
    "\n",
    "df_list = []\n",
    "for f in csv_files:\n",
    "    topo_num = int(f.split(\"_\")[1].split(\".\")[0])\n",
    "    temp = pd.read_csv(os.path.join(data_dir, f))\n",
    "    temp[\"topologi\"] = topo_num\n",
    "    df_list.append(temp)\n",
    "\n",
    "df_all = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
    "\n",
    "# ================== TARGET & FEATURE ==================\n",
    "target_cols = LABELS_ORDER[:]  # pakai urutan yang sama dengan rule-based\n",
    "\n",
    "exclude_cols = [\n",
    "    \"router_a\", \"router_b\", \"interface_a\", \"interface_b\",\n",
    "    \"ip_a\", \"ip_b\", \"subnet_a\", \"subnet_b\",\n",
    "    \"neighbor_a\", \"neighbor_b\", \"topologi\"\n",
    "] + target_cols\n",
    "\n",
    "feature_cols = [c for c in df_all.columns if c not in exclude_cols]\n",
    "\n",
    "# encode object columns\n",
    "df_encoded = df_all.copy()\n",
    "for col in feature_cols:\n",
    "    if df_encoded[col].dtype == \"object\":\n",
    "        df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col].astype(str))\n",
    "\n",
    "# ================== CROSS VALIDATION ==================\n",
    "results = []\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for topo in sorted(df_encoded[\"topologi\"].unique()):\n",
    "\n",
    "    df_train = df_encoded[df_encoded[\"topologi\"] != topo]\n",
    "    df_test  = df_encoded[df_encoded[\"topologi\"] == topo]\n",
    "\n",
    "    if df_train.empty or df_test.empty:\n",
    "        continue\n",
    "\n",
    "    X_train, y_train = df_train[feature_cols], df_train[target_cols].astype(int)\n",
    "    X_test,  y_test  = df_test[feature_cols], df_test[target_cols].astype(int)\n",
    "\n",
    "    # Train Random Forest (multi-output)\n",
    "    model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pd.DataFrame(model.predict(X_test), columns=target_cols, index=y_test.index)\n",
    "\n",
    "    # ===== PER-TOPO METRICS =====\n",
    "    subset_acc = accuracy_score(y_test, y_pred)\n",
    "    hamming_l = hamming_loss(y_test, y_pred)\n",
    "    hamming_acc = 1 - hamming_l\n",
    "\n",
    "    micro_prec = precision_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "    micro_rec  = recall_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "    micro_f1   = f1_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "\n",
    "    macro_prec = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    macro_rec  = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    macro_f1   = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    weighted_prec = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    weighted_rec  = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    weighted_f1   = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    results.append({\n",
    "        \"topologi\": topo,\n",
    "        \"subset_accuracy\": subset_acc,\n",
    "        \"hamming_accuracy\": hamming_acc,\n",
    "        \"hamming_loss\": hamming_l,\n",
    "        \"micro_precision\": micro_prec,\n",
    "        \"micro_recall\": micro_rec,\n",
    "        \"micro_f1\": micro_f1,\n",
    "        \"macro_precision\": macro_prec,\n",
    "        \"macro_recall\": macro_rec,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"weighted_precision\": weighted_prec,\n",
    "        \"weighted_recall\": weighted_rec,\n",
    "        \"weighted_f1\": weighted_f1\n",
    "    })\n",
    "\n",
    "    all_y_true.append(y_test)\n",
    "    all_y_pred.append(y_pred)\n",
    "\n",
    "# ================== GLOBAL METRICS (GABUNG SEMUA BARIS) ==================\n",
    "df_results = pd.DataFrame(results)\n",
    "summary_cv_mean = df_results.mean(numeric_only=True)  # rata-rata per-topologi (fold)\n",
    "\n",
    "y_true_all = pd.concat(all_y_true, ignore_index=True)\n",
    "y_pred_all = pd.concat(all_y_pred, ignore_index=True)\n",
    "\n",
    "# confusion matrix per label\n",
    "mcm = multilabel_confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "def safe_div(a, b):\n",
    "    return a / b if b else 0.0\n",
    "\n",
    "per_label = OrderedDict()\n",
    "sum_tp = sum_fp = sum_fn = sum_tn = 0\n",
    "\n",
    "for i, label in enumerate(target_cols):\n",
    "    TN, FP, FN, TP = mcm[i].ravel()\n",
    "\n",
    "    support_pos = TP + FN\n",
    "    support_neg = TN + FP\n",
    "    support_all = support_pos + support_neg\n",
    "\n",
    "    prec = safe_div(TP, TP + FP)\n",
    "    rec  = safe_div(TP, TP + FN)\n",
    "    f1   = safe_div(2 * prec * rec, (prec + rec))\n",
    "    acc  = safe_div(TP + TN, support_all)\n",
    "\n",
    "    per_label[label] = {\n",
    "        \"tp\": TP,\n",
    "        \"fp\": FP,\n",
    "        \"fn\": FN,\n",
    "        \"tn\": TN,\n",
    "        \"precision\": round(prec, 4),\n",
    "        \"recall\": round(rec, 4),\n",
    "        \"f1\": round(f1, 4),\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"support_pos\": int(support_pos),\n",
    "        \"support_neg\": int(support_neg),\n",
    "        \"support_all\": int(support_all),\n",
    "    }\n",
    "\n",
    "    sum_tp += TP\n",
    "    sum_fp += FP\n",
    "    sum_fn += FN\n",
    "    sum_tn += TN\n",
    "\n",
    "# macro dari per_label\n",
    "if per_label:\n",
    "    macro_p = sum(v[\"precision\"] for v in per_label.values()) / len(per_label)\n",
    "    macro_r = sum(v[\"recall\"]    for v in per_label.values()) / len(per_label)\n",
    "    macro_f1= sum(v[\"f1\"]        for v in per_label.values()) / len(per_label)\n",
    "    macro_acc = sum(v[\"accuracy\"] for v in per_label.values()) / len(per_label)\n",
    "else:\n",
    "    macro_p = macro_r = macro_f1 = macro_acc = 0.0\n",
    "\n",
    "# micro dari agregat TP/FP/FN/TN semua label\n",
    "micro_p = safe_div(sum_tp, sum_tp + sum_fp)\n",
    "micro_r = safe_div(sum_tp, sum_tp + sum_fn)\n",
    "micro_f1= safe_div(2 * micro_p * micro_r, (micro_p + micro_r))\n",
    "micro_jaccard = safe_div(sum_tp, (sum_tp + sum_fp + sum_fn))\n",
    "micro_acc_std  = safe_div(sum_tp + sum_tn, (sum_tp + sum_fp + sum_fn + sum_tn))\n",
    "\n",
    "# subset accuracy global (rata2 per-topologi)\n",
    "subset_acc_mean = float(summary_cv_mean[\"subset_accuracy\"])\n",
    "hamming_acc_mean = float(summary_cv_mean[\"hamming_accuracy\"])\n",
    "\n",
    "summary_global = {\n",
    "    \"macro\": {\n",
    "        \"precision\": round(macro_p, 4),\n",
    "        \"recall\": round(macro_r, 4),\n",
    "        \"f1\": round(macro_f1, 4),\n",
    "        \"accuracy\": round(macro_acc, 4),\n",
    "    },\n",
    "    \"micro\": {\n",
    "        \"precision\": round(micro_p, 4),\n",
    "        \"recall\": round(micro_r, 4),\n",
    "        \"f1\": round(micro_f1, 4),\n",
    "        \"accuracy_jaccard\": round(micro_jaccard, 4),\n",
    "        \"accuracy_standard\": round(micro_acc_std, 4),\n",
    "    },\n",
    "    \"global_counts\": {\n",
    "        \"tp_total\": int(sum_tp),\n",
    "        \"fp_total\": int(sum_fp),\n",
    "        \"fn_total\": int(sum_fn),\n",
    "        \"tn_total\": int(sum_tn),\n",
    "    },\n",
    "    \"subset_accuracy\": {\n",
    "        \"mean_exact_match\": round(subset_acc_mean, 4),\n",
    "        \"mean_hamming_accuracy\": round(hamming_acc_mean, 4),\n",
    "        \"num_samples\": int(len(y_true_all)),\n",
    "        \"num_topologies\": int(len(df_results)),\n",
    "    },\n",
    "}\n",
    "\n",
    "# classification report (opsional, tetap dipertahankan)\n",
    "report = classification_report(\n",
    "    y_true_all, y_pred_all,\n",
    "    target_names=LABELS_ORDER,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "# ================== SAVE OUTPUT ==================\n",
    "with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    f.write(\"=== HASIL RANDOM FOREST CROSS-VALIDATION (100 Topologi) ===\\n\\n\")\n",
    "\n",
    "    # ---- Ringkasan per-topologi (fold CV) ----\n",
    "    f.write(\"== Ringkasan Per Topologi (Fold CV) ==\\n\")\n",
    "    f.write(df_results.to_string(index=False))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    # ---- Per-label (format mirip rule-based) ----\n",
    "    f.write(\"\\n== Per Label (Global, gabungan 100 topologi) ==\\n\")\n",
    "    f.write(\"Label                  | TP  FP  FN  TN  | Prec   Rec    F1     Acc    | Pos  Neg  All\\n\")\n",
    "    f.write(\"-\" * 96 + \"\\n\")\n",
    "    for lbl in LABELS_ORDER:\n",
    "        v = per_label[lbl]\n",
    "        f.write(\n",
    "            f\"{lbl:22} | \"\n",
    "            f\"{v['tp']:3} {v['fp']:3} {v['fn']:3} {v['tn']:3} | \"\n",
    "            f\"{v['precision']:.4f} {v['recall']:.4f} {v['f1']:.4f} {v['accuracy']:.4f} | \"\n",
    "            f\"{v['support_pos']:4} {v['support_neg']:4} {v['support_all']:4}\\n\"\n",
    "        )\n",
    "\n",
    "    # ---- Rata-rata macro/micro ----\n",
    "    f.write(\"\\n== Rata-rata (Macro) ==\\n\")\n",
    "    f.write(f\"Macro Precision       : {summary_global['macro']['precision']}\\n\")\n",
    "    f.write(f\"Macro Recall          : {summary_global['macro']['recall']}\\n\")\n",
    "    f.write(f\"Macro F1-Score        : {summary_global['macro']['f1']}\\n\")\n",
    "    f.write(f\"Macro Accuracy        : {summary_global['macro']['accuracy']}\\n\")\n",
    "\n",
    "    f.write(\"\\n== Metrik Mikro (Global) ==\\n\")\n",
    "    f.write(f\"Micro Precision       : {summary_global['micro']['precision']}\\n\")\n",
    "    f.write(f\"Micro Recall          : {summary_global['micro']['recall']}\\n\")\n",
    "    f.write(f\"Micro F1-Score        : {summary_global['micro']['f1']}\\n\")\n",
    "    f.write(f\"Micro Accuracy Jaccard: {summary_global['micro']['accuracy_jaccard']}\\n\")\n",
    "    f.write(f\"Micro Accuracy Std    : {summary_global['micro']['accuracy_standard']}\\n\")\n",
    "\n",
    "    # ---- TN & subset accuracy ----\n",
    "    f.write(\"\\n== TN & Subset Accuracy ==\\n\")\n",
    "    f.write(\n",
    "        f\"Total TP/FP/FN/TN     : \"\n",
    "        f\"{summary_global['global_counts']['tp_total']}/\"\n",
    "        f\"{summary_global['global_counts']['fp_total']}/\"\n",
    "        f\"{summary_global['global_counts']['fn_total']}/\"\n",
    "        f\"{summary_global['global_counts']['tn_total']}\\n\"\n",
    "    )\n",
    "    f.write(\n",
    "        f\"Subset Accuracy (Exact Match, mean per topologi) : \"\n",
    "        f\"{summary_global['subset_accuracy']['mean_exact_match']}\\n\"\n",
    "    )\n",
    "    f.write(\n",
    "        f\"Hamming Accuracy (mean per topologi)            : \"\n",
    "        f\"{summary_global['subset_accuracy']['mean_hamming_accuracy']}\\n\"\n",
    "    )\n",
    "    f.write(\n",
    "        f\"Total Sampel (baris dataset)                   : \"\n",
    "        f\"{summary_global['subset_accuracy']['num_samples']}\\n\"\n",
    "    )\n",
    "    f.write(\n",
    "        f\"Total Topologi (fold CV)                       : \"\n",
    "        f\"{summary_global['subset_accuracy']['num_topologies']}\\n\"\n",
    "    )\n",
    "\n",
    "    # ---- Classification report (opsional) ----\n",
    "    f.write(\"\\n=== CLASSIFICATION REPORT (GLOBAL) ===\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "    f.write(\"\\nWaktu Eksekusi: \" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "print(f\"[✓] Semua metrik + TP/FP/FN/TN berhasil disimpan ke: {output_txt}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
